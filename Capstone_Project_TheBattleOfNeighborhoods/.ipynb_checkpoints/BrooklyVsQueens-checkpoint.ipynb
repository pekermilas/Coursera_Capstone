{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Get Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required libraries FOR:\n",
    "\n",
    "#data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from os import path\n",
    "\n",
    "#web scraping\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#plotting maps\n",
    "#!conda install -c conda-forge folium --yes\n",
    "#I have Ubuntu on my laptop so \n",
    "#!pip3 install folium\n",
    "import folium\n",
    "\n",
    "#retrieving latitude-longitude of Neighbors\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "#clustering\n",
    "#!pip3 install --upgrade scipy\n",
    "#!pip3 install --upgrade scikit-learn\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#getting data and conversion from JSON\n",
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "#plotting libraries\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists('newyork_data.json'):\n",
    "    !wget -q -O 'newyork_data.json' https://cocl.us/new_york_dataset\n",
    "else:\n",
    "    print(\"Data is already downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newyork_data.json') as json_data:\n",
    "    newyork_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataframe columns\n",
    "column_names = ['Borough', 'Neighborhood', 'Latitude', 'Longitude'] \n",
    "\n",
    "# instantiate the dataframe\n",
    "neighborhoods = pd.DataFrame(columns=column_names)\n",
    "neighborhoods_data = newyork_data['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in neighborhoods_data:\n",
    "    borough = neighborhood_name = data['properties']['borough'] \n",
    "    neighborhood_name = data['properties']['name']\n",
    "        \n",
    "    neighborhood_latlon = data['geometry']['coordinates']\n",
    "    neighborhood_lat = neighborhood_latlon[1]\n",
    "    neighborhood_lon = neighborhood_latlon[0]\n",
    "    \n",
    "    neighborhoods = neighborhoods.append({'Borough': borough,\n",
    "                                          'Neighborhood': neighborhood_name,\n",
    "                                          'Latitude': neighborhood_lat,\n",
    "                                          'Longitude': neighborhood_lon}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_neigh = neighborhoods[neighborhoods['Borough']=='Queens'].reset_index(drop=True)\n",
    "brook_neigh = neighborhoods[neighborhoods['Borough']=='Brooklyn'].reset_index(drop=True)\n",
    "\n",
    "#bronx_neigh.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot regions of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'New York City, NY'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"ny_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of New York City are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of New York using latitude and longitude values\n",
    "map_newyork = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "\n",
    "# add markers for queens to map (blue)\n",
    "for lat, lng, borough, neighborhood in zip(queen_neigh['Latitude'], queen_neigh['Longitude'], queen_neigh['Borough'], queen_neigh['Neighborhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_newyork)  \n",
    "\n",
    "# add markers for brooklyn to map (red)\n",
    "for lat, lng, borough, neighborhood in zip(brook_neigh['Latitude'], brook_neigh['Longitude'], brook_neigh['Borough'], brook_neigh['Neighborhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='#cc3139',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_newyork)  \n",
    "\n",
    "map_newyork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Venues Data from Foursquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'RYCX141XUBTJKRVJMLA51KZVARP4KANFZDUVGY4SNPBT0JV0' # your Foursquare ID\n",
    "CLIENT_SECRET = 'BRS3PNN0IUEIUAJ4LYDWJ0EWFVVA22FKZMCUHC4331QBADIH' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "#print('Your credentails:')\n",
    "#print('CLIENT_ID: ' + CLIENT_ID)\n",
    "#print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(borough,names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    LIMIT=200\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        #print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        fname = '%s' % name\n",
    "        if not path.exists('Data/'+borough+fname.replace(\" \",\"\")+'.json'):\n",
    "            results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "            with open('Data/'+borough+fname.replace(\" \",\"\")+'.json', 'w') as f:\n",
    "                json.dump(results, f)\n",
    "        else:\n",
    "            #print('File {} exists!'.format('Data/'+fname.replace(\" \",\"\")+'.json'))\n",
    "            with open('Data/'+borough+fname.replace(\" \",\"\")+'.json') as f:\n",
    "              results = json.load(f)\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name'],\n",
    "            v['venue']['categories'][0]['icon']['prefix']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category',\n",
    "                  'prefix']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_venues = getNearbyVenues('Queens/',names=queen_neigh['Neighborhood'],\n",
    "                                   latitudes=queen_neigh['Latitude'],\n",
    "                                   longitudes=queen_neigh['Longitude']\n",
    "                                  )\n",
    "brook_venues = getNearbyVenues('Brooklyn/',names=brook_neigh['Neighborhood'],\n",
    "                                   latitudes=brook_neigh['Latitude'],\n",
    "                                   longitudes=brook_neigh['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 : Food Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick only venues categorized under \"Food\"\n",
    "brook_food_venues = pd.DataFrame(columns=list(brook_venues))[:-1]\n",
    "for i in range(brook_venues.shape[0]):\n",
    "    if not brook_venues.iloc[i]['prefix'].find('/food/')==-1:\n",
    "        brook_food_venues=brook_food_venues.append(brook_venues.iloc[i])\n",
    "brook_food_venues = brook_food_venues.drop(['prefix'],axis=1).reset_index(drop=True)\n",
    "\n",
    "queen_food_venues = pd.DataFrame(columns=list(queen_venues))[:-1]\n",
    "for i in range(queen_venues.shape[0]):\n",
    "    if not queen_venues.iloc[i]['prefix'].find('/food/')==-1:\n",
    "        queen_food_venues=queen_food_venues.append(queen_venues.iloc[i])\n",
    "queen_food_venues = queen_food_venues.drop(['prefix'],axis=1).reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split \"Food\" venues into Restaurants and Otherfood\n",
    "brook_restaurants = pd.DataFrame(columns=list(brook_food_venues))\n",
    "brook_otherfood = pd.DataFrame(columns=list(brook_food_venues))\n",
    "for i in range(brook_food_venues.shape[0]):\n",
    "    if not brook_food_venues.iloc[i]['Venue Category'].find('Restaurant')==-1:\n",
    "        brook_restaurants=brook_restaurants.append(brook_food_venues.iloc[i])\n",
    "    else:\n",
    "        brook_otherfood=brook_otherfood.append(brook_food_venues.iloc[i])\n",
    "brook_restaurants = brook_restaurants.reset_index(drop=True)\n",
    "brook_otherfood = brook_otherfood.reset_index(drop=True)\n",
    "\n",
    "queen_restaurants = pd.DataFrame(columns=list(queen_food_venues))\n",
    "queen_otherfood = pd.DataFrame(columns=list(queen_food_venues))\n",
    "for i in range(queen_food_venues.shape[0]):\n",
    "    if not queen_food_venues.iloc[i]['Venue Category'].find('Restaurant')==-1:\n",
    "        queen_restaurants=queen_restaurants.append(queen_food_venues.iloc[i])\n",
    "    else:\n",
    "        queen_otherfood=queen_otherfood.append(queen_food_venues.iloc[i])\n",
    "queen_restaurants = queen_restaurants.reset_index(drop=True)\n",
    "queen_otherfood = queen_otherfood.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Restaurant Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split restaurant types in to 15 groups based on their frequencies\n",
    "b_rest_freq_list=brook_restaurants['Venue Category'].value_counts(normalize=False).index.tolist()[:14]\n",
    "b_rest_freq_list.append('Others')\n",
    "b_rest_freqs=brook_restaurants['Venue Category'].value_counts(normalize=False).values.tolist()[:14]\n",
    "b_last = np.array(brook_restaurants['Venue Category'].value_counts(normalize=False).values.tolist()[14:]).sum()\n",
    "b_rest_freqs.append(b_last)\n",
    "\n",
    "q_rest_freq_list=queen_restaurants['Venue Category'].value_counts(normalize=False).index.tolist()[:14]\n",
    "q_rest_freq_list.append('Others')\n",
    "q_last = np.array(queen_restaurants['Venue Category'].value_counts(normalize=False).values.tolist()[14:]).sum()\n",
    "q_rest_freqs=queen_restaurants['Venue Category'].value_counts(normalize=False).values.tolist()[:14]\n",
    "q_rest_freqs.append(q_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_rest_freq_list, b_rest_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_rest_freq_list, q_rest_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
    "fig.subplots_adjust(left=None,right=None,wspace=0.8)\n",
    "fig.suptitle('Most common restaurants in Brooklyn and Queens',fontsize=20)\n",
    "plt.sca(axes[0])\n",
    "plt.barh(b_rest_freq_list[:-1][::-1],b_rest_freqs[:-1][::-1],color='#cc3139')\n",
    "plt.xticks(rotation=0,fontsize=14)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(['Brooklyn'],fontsize=16)\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.barh(q_rest_freq_list[:-1][::-1],q_rest_freqs[:-1][::-1],color='#3186cc')\n",
    "plt.xticks(rotation=0,fontsize=14)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(['Queens'],fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we compare food venues in both boroghs\n",
    "# data to plot\n",
    "n_groups = 3\n",
    "queen_food_vals = [queen_restaurants.shape[0],queen_otherfood.shape[0],queen_food_venues.shape[0]]\n",
    "brook_food_vals = [brook_restaurants.shape[0],brook_otherfood.shape[0],brook_food_venues.shape[0]]\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, queen_food_vals, bar_width,\n",
    "alpha=opacity,\n",
    "color='#3186cc',\n",
    "label='Queens')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, brook_food_vals, bar_width,\n",
    "alpha=opacity,\n",
    "color='#cc3139',\n",
    "label='Brooklyn')\n",
    "\n",
    "#plt.xlabel('Venue type')\n",
    "plt.ylabel('Venue counts',fontsize=16)\n",
    "plt.title('Food venue counts in Brooklyn and Queens',fontsize=18)\n",
    "plt.xticks(index + bar_width/2, ('Restaurants', 'Others', 'Total'),fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 : Art & Entertainment Venues (Not Finished Yet!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick only venues categorized under \"Arts & Entertainment\"\n",
    "brook_art_venues = pd.DataFrame(columns=list(brook_venues))[:-1]\n",
    "for i in range(brook_venues.shape[0]):\n",
    "    if not brook_venues.iloc[i]['prefix'].find('/arts_entertainment/')==-1:\n",
    "        brook_art_venues=brook_art_venues.append(brook_venues.iloc[i])\n",
    "brook_art_venues = brook_art_venues.drop(['prefix'],axis=1).reset_index(drop=True)\n",
    "\n",
    "queen_art_venues = pd.DataFrame(columns=list(brook_venues))[:-1]\n",
    "for i in range(queen_venues.shape[0]):\n",
    "    if not queen_venues.iloc[i]['prefix'].find('/arts_entertainment/')==-1:\n",
    "        queen_art_venues=queen_art_venues.append(queen_venues.iloc[i])\n",
    "queen_art_venues = queen_art_venues.drop(['prefix'],axis=1).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_art_venues['Venue Category'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 : Art & Entertainment Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brook_scho_venues = pd.DataFrame(columns=list(brook_venues))[:-1]\n",
    "for i in range(brook_venues.shape[0]):\n",
    "    if not brook_venues.iloc[i]['prefix'].find('University')==-1:\n",
    "        brook_scho_venues=brook_scho_venues.append(brook_venues.iloc[i])\n",
    "brook_scho_venues = brook_scho_venues.drop(['prefix'],axis=1).reset_index(drop=True)\n",
    "\n",
    "#queen_scho_venues = pd.DataFrame(columns=list(queen_venues))[:-1]\n",
    "#for i in range(queen_venues.shape[0]):\n",
    "#    if not queen_venues.iloc[i]['prefix'].find('college')==-1:\n",
    "#        queen_scho_venues=queen_scho_venues.append(queen_venues.iloc[i])\n",
    "#queen_scho_venues = queen_scho_venues.drop(['prefix'],axis=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brook_neigh.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
